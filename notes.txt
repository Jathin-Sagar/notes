DevOps Notes
<<lsblk
lsblk to display block devices
lsblk -a To display empty block devices.  
lsblk -b print size in bits
lsblk -z print zone model
lsblk -d skip slave entries
lsblk -i to use ascii characters for tree formation
lsblk -m  To print information about device owner, group, and mode of block devices.  
lsblk -o SIZE,NAME,MOUNTPOINT To print selected columns of block-devices. 
lsblk -dn hide column headings
lsblk -help display help section
lsblk
<<tar 
(tape archive)
the command iThe tar command is often used for creating compressed archive files that can be easily transferred or stored. It can compress multiple files into a single archive file, and the resulting archive can be compressed using different compression algorithms like gzip, bzip2, and xz to reduce its size.s used for creating archive and extracting the archive files it was originally used to create backups to tape drives.
tar cvf create,verbose so it gets update, filename(flag) file.tar hello.txt it shown in the red colour, it is a uncompresed tar archive.
tar xvf file.tar extracts files through archives
tar cvzf file.tar.gz hello.txt it makes a tar file kown as file.tar.gz it is the archive of hello.txt file
tar xvzf file.tar.gz it is used to extract the files through file.tar.gz archives file
tar cvfj file.tar.tbz hello.txt making compressed tar files with the -j option
tar -xvf file.tar -c / tar -xvf file.tar  path of directory used to untar( command which enable the users to extract files that are compressed with tar ,tar.gz)
tar -jxvf file.tar.tbz "hello.txt" untar multiple .tar.tbz, .tar.gz, .tar extract more than one file
tar -czf - file.tar./gz/tbz | wc -c it is used to see the size of archive files in kilobytes
tar rvf file.tar hello.txt updating an existing tar file
tar tf file.tar list the whole archive files
tar -tvf file.tar view the archive
tar tvf file.tar hello.txt  view the archived files with their information
tar tvf file.tar | grep "file.txt" help us to only list the mentioned image or text in grep through archived files.
wildcards are referred to as a wildcard character or wild character in Linux. It is a symbol that is used for representing or replacing multiple characters.
Typically, wildcards are either a question mark (?) which illustrates an individual character or an asterisk (*) which illustrates multiple characters.
tar tvf file.tar --wildcards '*.png' finding a .png image
 tar --delete -f file.tar hello.txt to remove files and a tar archive.
tar
<<cronjobs  

A scheduling tool is a software application or program used to automate and manage tasks that need to be performed at specific times or intervals. Scheduling tools are commonly used to streamline and optimize workflows, reduce errors, and save time and effort for users.

There are many types of scheduling tools available, ranging from simple task scheduling tools like the Unix cron utility to more complex project management software and workflow automation platforms.

Scheduling tools typically allow users to set up recurring tasks, assign resources, and set deadlines or timelines for completion. They may also include features for tracking progress, sending notifications or reminders, and generating reports or analytics.

Some common types of scheduling tools include:

Calendar and appointment scheduling tools: These tools allow users to schedule appointments, meetings, and other events. They may include features for sending reminders, tracking attendance, and rescheduling appointments if needed.

Task scheduling tools: These tools allow users to schedule and automate routine tasks, such as data backups, software updates, or system maintenance tasks.

Project management tools: These tools are designed to manage project timelines, deadlines, and milestones. They may include features for scheduling tasks, assigning resources, and tracking progress towards project goals.

Workforce management tools: These tools are used to manage staff schedules, assign tasks, and track employee time and attendance. They may also include features for managing payroll, benefits, and other HR functions.

Overall, scheduling tools are essential for managing complex workflows and ensuring that tasks are completed efficiently and on time. They are used in a wide range of industries and settings, including business, education, healthcare, and government.
Crontab Operators
Cron syntax also utilizes operators for performance. Operators are large inland that operates effectively on the Cron attribute values. The operators are discussed below-

Asterisk operator (*)
The asterisk operator denotes any significance or already. Suppose you see an asterisk (*) in the Hour domain, it implies the job will be done every hour. It represents all values. Utilization of this operator is to gather operating for the entire month or week.

Comma Operator (,)
You can stipulate a range of items for regurgitation using the comma operator. It also defines distinct unique values.

For Instance, if you enter 2,5,8 in the Hour domain, the assignment will execute at 2 a.m., 5 a.m., and 8 a.m.

Hyphen Operator (-)
You can stipulate a set of outcomes using the hyphen operator. If you enter 2-5 in the Weekday domain, the assignment will execute every weekday (From Tuesday to Friday). It also represents a set of parameters.

Forward slash Operator (/)
The slash operator allows you to specify values that will be repeated over a specific interval between them. This operator can also be used to separate a number into various stages.

For example, if you have */4 in the Hour field, it means the action will be performed every four hours.

It is also equivalent as clarifying 0,4,8,12,16,20. You can utilize a range of data rather than an asterisk even before the slash operator.

For example, 1-30/10 indicates the similar as 1,11,21.

<<unzip
through cmd and also in the system (graphical interface)we can unzip the files,we can extracting compressed files from a ZIP archive. ZIP files are a popular format for compressing and packaging files together, making them easier to transfer and store.
The primary reason for using ZIP files is to save storage space and reduce transfer. 
unzip archive.zip this command is used to unzip the files
unzip archive.zip -d myfiles this command is used to unzip file and save in a directory
unzip archive.zip file.txt unzipig the file and saving as text files
unzip

<<sed
The sed command (short for "stream editor") is a powerful utility in Linux and other Unix-based operating systems that can be used to modify text files.

The sed command is designed to read input files (either from standard input or from one or more files) and apply a set of commands to the text. The commands can be used to perform a wide range of text transformations, such as:

Replacing text: You can use the s command to search for a pattern in the text and replace it with a new string. For example, the command sed 's/hello/goodbye/' will replace all occurrences of the word "hello" with "goodbye" in the input text.

Deleting lines: You can use the d command to delete lines that match a particular pattern. For example, the command sed '/pattern/d' will delete all lines that contain the pattern.

Inserting text: You can use the i command to insert new text before a specified line. For example, the command sed '2i\New line' will insert the text "New line" before the second line of the input text.

Appending text: You can use the a command to append new text after a specified line. For example, the command sed '2a\New line' will append the text "New line" after the second line of the input text.

Transforming text: You can use regular expressions and other sed commands to transform text in a wide range of ways.

The sed command can be used in combination with other Linux utilities to perform complex text processing tasks. It is a powerful tool for manipulating text files and automating text processing tasks on the command line
echo class7 | sed 's/class/jtp/'  here class is changed to jtp
echo class7 | sed 's/7/10/'    in this 7 is changed to 10
 cat msg.txt | sed 's/learn/study/'    in the text file we changed lern word to study
echo class7 class9 | sed 's/class/jtp/g' here /' it only edits one file /g' it changes all the files to jtp   
cat msg.txt | sed 's/learn/study/g'   it only edits one text /g' it changes all the texts to study
cat msg.txt | sed '/jtp/d'    deleting line of jtp    
sed -e 's/red/blue/; s/yellow/black/' exm.txt  modifing multiple sed command
sed -f SedCommands exm.txt   we have used commands applied to the earlier example. So, the output is the same as the previous example
sed '3s/Red/Blue/' exm.txt  at which line we need to change we use this red is changed to blue
echo "Another Demo" | sed 'i\First Demo'  it will append the text
sed '3c\This is a modified line.' exm.txt  modifing the lines 
sed 'y/abc/def/' exm.txt  transfering the characters
sed '=' exm.txt  printing the line number
sed -n '/mango/=' exm.txt  it will display the line number with the word mango
sed
<<awk
The awk command is used for text processing in Linux. Although, the sed command is also used for text processing, but it has some limitations, so the awk command becomes a handy option for text processing. It provides powerful control to the data.

The Awk is a powerful scripting language used for text scripting. It searches and replaces the texts and sorts, validates, and indexes the database.
awk '{ print "Welcome to awk command"}' The above command will print the inputted string every time we execute the command. Press CTRL+D key to terminate the program
cat > student.txt  
Sam CS  
Daniel IT  
John IT  
Arya IT  
Mike ECE  
Helena ECE  
awk '/cs/ {print}' student.txt list the students with specific patterns like cs ece first we need to create file with cat
awk '{print}' student.txt to see all the files
awk '{print $1,$5}' student.txt this command will print the column 1 and 5
NR: It is used to show the current count of the lines. The awk command performs action once for each line. These lines are said as records.

NF: It is used to count the number of fields within the current database.

FS: It is used to create a field separator character to divide fields into the input lines.

OFS: It is used to store the output field separator. It separates the output fields.

ORS: It is used to store the output record separator. It separates the output records. It prints the content of the ORS command automatically.
awk '{print NR $2}' student.txt display line number and column of the given number
awk '{print $NF}' student.txt print the last fileld of the file
awk 'BEGIN { ORS ="-"} {print $0}' student.txt seperate the output by _underscore
awk 'BEGIN { for(i=1;i<=8;i++) print "square of", i, "is",i*i; }' print the square of 1 to 8.
Sam,75,100  
Daniel,80,100  
John,74,100  
Arya,85,100  
Mike,70,100   
Helena,74,100 
awk -F"," '{x+=$3}END{print x}' student.txt  to find out the total marks of the students
awk -F, '{a[$1]+=$2;}END{for(i in a)print i", "a[i];}' student.txt print the individual's name with his marks
awk 'BEGIN{x=exp(8); print x}'   print the value of exp 8

awk
<<ls
ls > bharath in this all the files contains in the directory is shown in bharath with cat jathin we can see it
1>&and percentile directory (standared output stdout)/2 &>and percentile directory (standared error stderr) sai now the file is getting created we can see it by using less or more command but , we can use gedit it opens the file in the folder  , 1 > sai for this we get the command not found
ls
1 > filename 2 >& 1 in this both the standard output and standard error is send to the file name
<<uname
The command ‘uname‘ displays the information about the system
uname -a  It prints all the system information in the following order: Kernel name, network node hostname, kernel release date, kernel version, machine hardware name, hardware platform, operating system
uname -s print kernal name
uname -n print hostname
uname -r print kernal release date
uname -v version of the current kernel
uname -m print machine hardware name
uname -p print machine processor
uname -i print the platform of hardware
uname -o print the name of the operating system
uname

<<$
echo is used infront of all the variables
$$ pid of the current shell
$! pid if last background command
$? existing status of the last command executed
$0 filenam eof the current script
$n/1/2 these variable corresponds to the argument with which a script was invoked.her n is a positive decimal number corresponding to the position of an argument ex 1st is 1 2nd s 2
$# number of arguments supplied to a script
$* all the arguments are double quotes,if the script recives 2 arguments then $* is equalent to $1 $2
$@all the arguments are individually double quoted if a script recives two arguments $@ is equivalent to$1 $2
$SHELL is a special shell variable that contains the pathname of the user's preferred shell.
cat /etc/shells  The list of all the shells which are currently installed in our Linux system is stored in the ‘shells’ file which is present in /etc folder of the system. It has read-only access by default and is modified automatically whenever we install a new shell in our system. As we can see, the cat command displays the various installed shells along with their installation paths..
In Unix-like operating systems, echo {A} and echo "{A}" are different in terms of how the shell performs brace expansion and variable expansion.
<< echo {A} and echo "{A}"
echo {A} is an example of brace expansion, which is a feature of many Unix shells that allows you to generate a list of strings by specifying a pattern inside curly braces. In this case, the pattern is a single character "A", so brace expansion generates a list that contains just the string "A". When you run the echo command with this argument, it simply prints the string "A" to the terminal.

echo "{A}" is an example of a string literal that contains the character sequence "{A}". When you run the echo command with this argument, it simply prints the string "{A}" to the terminal, without any further expansion or processing.

In summary, echo {A} generates a list of strings using brace expansion and prints the resulting string to the terminal, while echo "{A}" simply prints a string literal to the terminal without any expansion.
echo {A} and echo "{A}"
{A} it has some expansion ,"{A}" it don't have any expansion

<< #!/bin/bash
#!/bin/ env bash
The main difference between the two is that #!/usr/bin/bash specifies the absolute path to the Bash interpreter, while #!/usr/bin/env bash uses the env command to locate the Bash interpreter in the user's PATH environment variable.Using #!/usr/bin/bash assumes that Bash is installed in the /usr/bin/ directory, which may not always be the case on different systems. On some systems, Bash may be installed in a different directory, which could cause the script to fail.

Using #!/usr/bin/env bash is a more portable option as it searches for the Bash interpreter in the PATH environment variable, which is a list of directories that the shell searches for executables. This makes the script more adaptable to different systems and makes it easier to maintain.
#!/bin/env bash
#!/bin/bash

<<verify user root or not
The command $(id -u)" -eq 0 is used to check if the current user has root privileges (i.e., is the superuser or administrator).

In Unix-based systems, every user is assigned a unique numeric user ID (UID) that is used to identify the user. The root user (superuser or administrator) has a UID of 0, while regular users have UIDs that are greater than 0.

The id -u command is used to retrieve the UID of the current user. The $() syntax is used to capture the output of the command and use it as a variable. The expression " -eq 0" is a comparison operator that checks if the UID is equal to 0.

So, when the command $(id -u)" -eq 0 is executed, it returns a value of 0 if the current user has root privileges, and a value of 1 (or some other non-zero value) if the current user does not have root privileges.

This command is commonly used in shell scripts to perform actions that require root privileges, such as installing software, modifying system settings, or accessing restricted files and directories. By checking if the current user has root privileges before performing such actions, the script can avoid potential errors or security risks.
verify user root or not

#difference between [] and [[]]
[ and [[ can be used for conditional expressions, [[ is a more powerful and flexible option that is specific to Bash. [ is more portable and can be used in other shells.
#set -n, set -x, set -e, and set +x are all options that can be used in Bash shell scripts to modify the behavior of the shell.

set -n (or set -o noexec) prevents the execution of commands in the script. When this option is set, the shell reads and checks the syntax of the script, but does not execute any of the commands. This can be useful for checking the syntax of a shell script without actually running it.

set -x (or set -o xtrace) enables tracing of commands in the script. When this option is set, the shell prints each command to the terminal as it is executed, preceded by the value of the PS4 variable (which defaults to +).

set -e (or set -o errexit) causes the script to exit immediately if any command exits with a non-zero status (i.e., if an error occurs). This can be useful for catching errors early in the script and preventing unintended consequences.

set +x disables tracing of commands in the script. This option is used to turn off the set -x option when it is no longer needed.

It is worth noting that these options are not exclusive and can be used together in a script. For example, it is common to use set -e and set -x together to catch errors and trace the execution of a script at the same time. The options can be set and unset as needed throughout the script using the set command.

<</etc/profile 

/etc/profile is a system-wide initialization script for Bash that is executed for all users when they log in to the system. It is located in the /etc directory, which is typically only accessible by the system administrator.

/etc/profile is used to set environment variables and aliases that are available to all users on the system. It may also contain system-wide settings and configurations for various applications and services.

In general, /etc/profile is used to set global environment variables, such as the PATH variable, which specifies the directories that the system will search when looking for executable programs. It may also set variables that are specific to certain applications or services that are installed on the system.

Since /etc/profile is executed for all users when they log in, it is important to be careful when making changes to this file, as they may affect all users on the system. It is a good practice to back up the file before making any changes, and to test any changes in a non-production environment before applying them to a live system.
  --it gives us inbuilt information about the root privileges in a script formate.
/etc/profile 

<<uniq
The uniq command in Linux is a command-line utility that reports or filters out the repeated lines in a file. 
In simple words, uniq is the tool that helps to detect the adjacent duplicate lines and also deletes the duplicate lines. uniq filters out the adjacent matching lines from the input file(that is required as an argument) and writes the filtered data to the output file. 
uniq murali.txt example
 

-c – -count : It tells how many times a line was repeated by displaying a number as a prefix with the line.
-d – -repeated : It only prints the repeated lines and not the lines which aren’t repeated.
-D – -all-repeated[=METHOD] : It prints all duplicate lines and METHOD can be any of the following: 
none : Do not delimit duplicate lines at all. This is the default.
prepend : Insert a blank line before each set of duplicated lines.
separate : Insert a blank line between each set of duplicated lines.
-f N – -skip-fields(N) : It allows you to skip N fields(a field is a group of characters, delimited by whitespace) of a line before determining the uniqueness of a line.
-i – -ignore case : By default, comparisons done are case sensitive but with this option case insensitive comparisons can be made.
-s N – -skip-chars(N) : It doesn’t compare the first N characters of each line while determining uniqueness. This is like the -f option, but it skips individual characters rather than fields.
-u – -unique : It allows you to print only unique lines.
-z – -zero-terminated : It will make a line end with 0 bytes (NULL), instead of a newline.
-w N – -check-chars(N) : It only compares N characters in a line.
– – help : It displays a help message and exit.
– – version : It displays version information and exit.

uniq
 
<<alias
alias command instructs the shell to replace one string with another string while executing the commands. 

When we often have to use a single big command multiple times, in those cases, we create something called as alias for that command. Alias is like a shortcut command which will have same functionality as if we are writing the whole command. 
alias 1="cd Documents"
unalias 1
alias -p it will show all the aliases

alias
<<sort
sort weeks.txt  to sort the files in alphabetical order.
sort -k1 states.txt If a file has more than one column, column number is used to sort a specific column.
sort -n -k2 marks.txt Numeric sorting is different from alphabetical sorting. For numeric sorting option 'n' is used along with the column number if required.

sort

<<uniq
sort dupil.txt | uniq remove repeated lines
sort dupil.txt | uniq -c counts the number of times a word is repeating.
sort dupil.txt | uniq -d only the displayed lines 
sort dupil.txt | uniq -u only display the uniq lines
sort dupil.txt | uniq -s 2 ignore the first 2 characters 
uniq -f 2 dupil.txt The above command will not compare the first two fields from the file dupli.txt.

uniq

<< port number
A port number is a 16-bit unsigned integer that identifies a specific process to which a network message should be delivered within a computer network. It is used to distinguish between different network services that may be running on the same network device, such as a computer or a router.

port number         servicename        transport protocol         Description
7                   Echo                TCP,UDP                   echo services
21                  FTP                 TCP,SCTP                  file transfer protocol data transfer
22                  SSH-SCP             TCP,UDP,SCTP              Secure Shell, secure logins, file transfers                                                                       (scp, sftp), and port forwarding
23                  TELNET              TCP,UDP,SCTP              Telnet protocol—unencrypted text communications
25                  SMTP                TCP                       Simple Mail Transfer Protocol, used for email                                                                     routing between mail servers
53                  DNS                 TCP,UDP                   Domain Name System name resolver
80                  HTTP                TCP,UDP,SCTP              Hypertext Transfer Protocol (HTTP) uses TCP in                                                                     versions 1.x and 2. HTTP/3 uses QUIC, a                                                                           transport protocol on top of UDP
443                 HTTPS over SSL      TCP,UDP,SCTP              Hypertext Transfer Protocol Secure (HTTPS) uses                                                                   TCP in versions 1.x and 2. HTTP/3 uses QUIC, a                                                                     transport protocol on top of UDP.
465                 SMTP over TLS/SSL,  TCP                       Authenticated SMTP over TLS/SSL (SMTPS), URL                         SSM                                           Rendezvous Directory for SSM (Cisco protocol)
587                 SMTP                TCP                       Email message submission
989                 FTP over SSL        TCP,UDP                   FTPS Protocol (data), FTP over TLS/SSL
990                 FTP over SSL        TCP,UDP                   FTPS Protocol (control), FTP over TLS/SSL
The FTPS data channel is used for transmitting file data, while the FTPS control channel is used for transmitting control information about the file transfer process. Both channels are encrypted using SSL/TLS to ensure the confidentiality and integrity of the data being transmitted.
1194                OpenVPN	            TCP,UDP                  	OpenVPN
3306                MySQL	              TCP                     	 MySQL database system
3389                RDP                RemoteDesktopProtocol(RDP) . RDP enables users to remotely connect to their                                                                   desktop computers from another device.
5432	               PostgreSQL          TCP	                      PostgreSQL database system



port
<<tcp
TCP (Transmission Control Protocol) is used for providing reliable and ordered delivery of data between applications running on hosts communicating over an IP network. Some of the main uses of TCP are:
Web browsing: When you visit a website using a web browser such as Chrome or Firefox, the browser establishes a TCP connection with the web server to request and receive the web page content. TCP ensures that the content is delivered reliably and in the correct order.
Email: When you send or receive email, your email client (such as Outlook or Gmail) uses TCP to establish a connection with the mail server and exchange email messages reliably and in the correct order.
File transfers: When you download or upload files over the internet using protocols such as FTP or SFTP, TCP is used to ensure that the files are transferred reliably and in the correct order.
Online gaming: Many online games use TCP to send and receive data between game clients and servers, to ensure that the game data is delivered reliably and in the correct order.
Overall, TCP is widely used in applications that require reliable and ordered data delivery, where the integrity and order of the data are critical for the proper functioning of the application.
tcp
<<udp
UDP (User Datagram Protocol) is a connectionless transport layer protocol in the Internet Protocol (IP) suite. Unlike TCP, UDP does not provide reliable delivery of data or guarantee that the data will be received in the correct order. UDP is used in applications where speed and efficiency are more important than reliability and ordered delivery.
Some common uses of UDP are:
Real-time multimedia applications: Applications such as voice over IP (VoIP), video conferencing, and online gaming often use UDP to transmit real-time data because of its low latency and fast transmission speed. In these applications, it is more important to have real-time delivery of data than to ensure that every packet is received and in order.
DNS (Domain Name System): UDP is used by the DNS protocol to quickly resolve domain names to IP addresses. When you type a domain name into your web browser, your computer sends a DNS query to a DNS server over UDP to obtain the IP address of the server that hosts the website.
DHCP (Dynamic Host Configuration Protocol): UDP is used by DHCP to assign IP addresses to devices on a network. When a new device joins a network, it sends a DHCP request over UDP to a DHCP server, which assigns it an IP address.
SNMP (Simple Network Management Protocol): SNMP is used to monitor and manage network devices such as routers, switches, and servers. UDP is used by SNMP to send management information between devices.
Overall, UDP is used in applications where speed and efficiency are more important than reliability and ordered delivery, and where occasional loss or duplication of packets is acceptable.
udp

<<sctp
SCTP (Stream Control Transmission Protocol) is a transport layer protocol that is designed to provide reliable, ordered, and flow-controlled delivery of messages between two endpoints. SCTP was developed as an alternative to TCP and UDP and is used in applications that require higher reliability and better congestion control than TCP, while also providing multi-homing support and improved security compared to UDP.
Some common uses of SCTP are:
Telecommunications: SCTP is used in telecommunications networks to transport signaling messages between network elements, such as switches and gateways. The reliable, ordered, and flow-controlled delivery of messages provided by SCTP ensures that signaling messages are delivered correctly and in the right order.
Real-time multimedia applications: SCTP is also used in real-time multimedia applications, such as voice and video conferencing, where the reliability and ordered delivery of messages is critical for maintaining the quality of the media stream.
Electronic payment systems: SCTP is used in electronic payment systems, such as credit card payment gateways, to ensure that payment transactions are processed securely and reliably.
Industrial control systems: SCTP is used in industrial control systems to transport control messages between devices in industrial networks. The reliable and ordered delivery of messages provided by SCTP is important for ensuring the safety and reliability of industrial processes.
Overall, SCTP is used in applications that require high reliability and improved congestion control, while also providing multi-homing support and improved security.

sctp
<<ifup
The ifup command basically brings the network interface up, allowing it to transmit and receive data. Technically ifup command is used to configure network interfaces based on interface definitions in the file /etc/network/interfaces.
sudo ifup -av , sudo is used for permissions, -a to work on all devices and v for verbose the output.
-a(–all): If used this option it affects all the interfaces marked as auto. Brings up interfaces in order they are defined /etc/network/interfaces. Combined with –allow, acts on all interfaces of a specified class instead.
–force: Force configuration or deconfiguration of the interface.
-V: Prints the version information.
-v: Verbose the output as they are executed.
ifup
<<ifdown
 ifdown command to bring network interface down, not allowing the user to transmit and receive data. Technically it places the network interface in a state where it cannot transmit or receive data. It is used to configure network interfaces based on interface definitions in the file /etc/network/interfaces.
sudo ifdown -av , sudo is used for permissions, -a to work on all devices and v for verbose the output.
-a(–all): This option is used to bring all the interface down which are defined in /etc/network/interfaces.
–allow=CLASS: This option will only allow interfaces listed in an allow-CLASS line in /etc/network/interfaces to be acted upon.
-v(–verbose): Show or verbose commands as they are executed.
-V(–version): Prints the Copyright and version information.

ifdown
 
<<ping
PING (Packet Internet Groper) command is used to check the network connectivity between host and server/host. This command takes as input the IP address or the URL and sends a data packet to the specified address with the message “PING” and get a response from the server/host this time is recorded which is called latency. Fast ping low latency means faster connection. Ping uses ICMP(Internet Control Message Protocol) to send an ICMP echo message to the specified host if that host is available then it sends ICMP reply message. Ping is generally measured in millisecond every modern operating system has this ping pre-installed. 
sudo ping -v To get ping version installed on your system. 
ping www.geeksforgeeks.org To stop pinging we should use ctrl+c otherwise it will keep on sending packets. 
ping -c 5 www.geeksforgeeks.org Controlling the number of pings
ping -s 40 -c 5 www.geeksforgeeks.org Controlling the size of packets send
ping -i 2 www.geeksforgeeks.org Changing the time interval
ping -c 5 -q www.geeksforgeeks.org To get only summary
ping -w 3 www.geeksforgeeks.org To Timeout PING
ping -f www.geeksforgeeks.org To send packets as soon as possible. This is used to test network performance. 
ping -c 5 -W 3 www.geeksforgeeks.org Sets time to wait for a response. 
ping -c 5 -p ff www.geeksforgeeks.org We can fill data in packet using -p option. Like -p ff will fill packet with ones.
ping -c 5 -M want www.geeksforgeeks.org It is a simple protocol to find out the maximum MTU(Maximum Transmission Unit) a TCP path can take. 
ping -c 5 -t 64 www.geeksforgeeks.org It is maximum hop a packet can travel before getting discarded.A value 0 will restricts packet to same host.

ping

<<ethtool
ethtool is a networking utility on Linux. It is used to configure Ethernet devices on Linux. ethtool can also be used to find a lot of information about connected Ethernet devices on your Linux computer.Ethtool is a Linux command line tool used to view and modify various parameters of the network interface controllers (NICs) on a system. It allows you to gather information about the NIC's driver, firmware version, link status, speed, duplex, and more. Additionally, ethtool can be used to configure various settings of the NIC, such as the speed and duplex mode, auto-negotiation, and wake-on-LAN (WOL) settings. Ethtool can be useful for diagnosing and troubleshooting network connectivity issues, as well as for optimizing network performance by fine-tuning the NIC's settings.
sudo ethtool --version you can check whether ethtool is installed already
sudo ethtool enp6s0 a lot of information about the network interface card
sudo ethtool -i enp6s0  to check for the driver used by one of your NIC
sudo ethtool -S enp6s0 Display Network Usage Statistics with ethtool:

ethtool

<<portbonding
Port bonding, also known as link aggregation or network bonding, is a technique used in computer networking to combine multiple physical network connections into a single logical connection. This is done to increase the overall bandwidth and reliability of the network connection.
In port bonding, two or more network ports on a device are linked together to form a single high-bandwidth connection. This can be accomplished using different techniques, such as Round-Robin, where the traffic is distributed equally between the ports, or Link Aggregation Control Protocol (LACP), which provides automatic detection and configuration of the port bonding.
Port bonding is commonly used in high-performance computing environments, data centers, and other settings where high network bandwidth and reliability are critical. It allows for improved network redundancy, load balancing, and fault tolerance, which can result in improved network performance and uptime.

portbonding

<<wget

Option	Function
wget <URL>	Download single file
wget -O <fileName> <URL>	Store with a different file name
wget --limit-rate=<Numberk> <URL>	Specify download rate/speed
wget -c <URL>	Complete the remaining downloaded file
wget -b <URL>	Download in background
wget --tries=<Number> <URL>	Set retrying attempts
wget -i <fileName>	Download multiple files
wget --mirror -p --convert-links -P ./local dir <webURL>	Download full website
wget --reject=<rejectingFile> <URL>	Reject a type of file
wget -Q<Value>m -i <fileName>	Quit downloading on exceeding certain limit
wget -r -A.<fileType> <webURL>	Download certain file type
wget -o <logFile> <URL>	Redirect downloading file to the log file

wget
<<curl
The curl command is a powerful command-line tool for transferring data to and from web servers. It supports a wide range of protocols, including HTTP, HTTPS, FTP, SMTP, and more.
Some of the common use cases for the curl command include:
Downloading files from the web: curl can be used to download files from web servers via HTTP, HTTPS, FTP, and other protocols.
Uploading files to the web: curl can also be used to upload files to web servers, such as for backup or synchronization purposes.
Debugging web services: curl can be used to test and debug web services, by sending requests and receiving responses from web servers.
Automating web-related tasks: curl can be used to automate various web-related tasks, such as monitoring website availability, testing web application functionality, and more.
Overall, curl is a versatile and powerful tool for working with web servers, and it can be particularly useful for automation and scripting of web-related tasks.

curl
<<ftp
FTP stands for File Transfer Protocol. It is a standard protocol used for transferring files over the internet between computers. FTP is commonly used for uploading and downloading files to and from web servers.
FTP works by establishing a connection between a client (such as a web browser or FTP client software) and a server (such as a web server or FTP server). The client sends commands to the server to initiate file transfers, create and delete directories, and perform other operations.
FTP supports two modes of operation: active and passive. In active mode, the client initiates the data connection to the server, while in passive mode, the server initiates the data connection to the client. Passive mode is more commonly used today, as it is more firewall-friendly.
FTP also supports authentication mechanisms such as usernames and passwords, and can use encryption to secure the data being transferred.
While FTP is still widely used, it has been largely replaced by more secure and efficient protocols such as SFTP (Secure File Transfer Protocol) and FTPS (FTP over SSL/TLS).

ftp
<<scp
scp (secure copy) command in Linux system is used to copy file(s) between servers in a secure way. The SCP command or secure copy allows secure transferring of files in between the local host and the remote host or between two remote hosts. It uses the same authentication and security as it is used in the Secure Shell (SSH) protocol. SCP is known for its simplicity, security and pre-installed availability.
scp –P port: Specifies the port to connect on the remote host.
scp –p: Preserves modification times, access times, and modes from the original file.
scp –q: Disables the progress meter.
scp –r: Recursively copy entire directories.
scp –S program: Name of program to use for the encrypted connection. The program must understand ssh(1) options.
scp –v: Verbose mode. Causes scp and ssh to print debugging messages about their progress. This is helpful in debugging connection, authentication, and configuration problems.

scp

<<rsync
rsync or remote synchronization is a software utility for Unix-Like systems that efficiently sync files and directories between two hosts or machines. One of them being the source or the local-host from which the files will be synced, the other one being the remote-host, on which synchronization will take place. There are basically two ways in which rsync can copy/sync data:
Copying/syncing to/from another host over any remote shell like ssh, rsh.
Copying/Syncing through rsync daemon using TCP.
Rsync is famous for its delta-transfer algorithm, in which it copies only the differences between the source files present in the local-host and the existing files in the destination or the remote host.
rsync local-file user@remote-host:remote-file
rsync Documents/ it will show list same as ls -l
rsync -avh Documents/ jathin The above command will copy/sync all the files and directories present in directory Documents to directory jathin. If the destination directory is not present (here jathin), rsync automatically creates one and copies all the data in it.
rsync -avhze ssh /foo user@remote-host:/tmp/Rsync using ssh: There are two different ways for rsync to contact a remote system:
Using a remote-shell program as the transport(such as ssh(Secure Shell) or rsh(Remote Shell)).
Contacting an rsync daemon directly via TCP.
rsync -avhe ssh --chown=USER:GROUP /foo user@remote-host:/tmp/Rsync with particular file permissions: If we want to sync files to the local or remote host with the permissions of the files being changed. The following command must be used.
rsync

<<rpm
In Linux, RPM (Red Hat Package Manager) is a package management system used for installing, updating, and removing software packages on Red Hat-based distributions such as Red Hat Enterprise Linux, CentOS, Fedora, and others.
RPM is designed to automate the process of installing, upgrading, and removing software packages, and it is used to manage both the software itself as well as its dependencies. Each software package is stored in an RPM file, which contains the software and all the necessary information to install it on a Linux system.
With RPM, you can install a package by simply running the command "rpm -i package_name.rpm", where "package_name.rpm" is the name of the RPM file. You can also use RPM to query information about installed packages, update packages, and remove packages from the system.
RPM also allows you to verify the integrity of installed packages, and it provides tools for managing software repositories, which are collections of packages that can be installed on a Linux system.
-q: It is used for querying any package.
-p: It is used for listing the capabilities that this package gives.
-R: This option is used for listing the capabilities over which the package depends.
rpm

<<yum
In Linux, YUM (Yellowdog Updater Modified) is a package management tool used for installing, updating, and removing software packages on Red Hat-based distributions such as Red Hat Enterprise Linux, CentOS, Fedora, and others.
YUM is based on RPM and is designed to simplify the process of managing software packages by resolving dependencies automatically. YUM is capable of downloading packages from repositories and installing them on the system along with their dependencies.
With YUM, you can install a package by simply running the command "yum install package_name", where "package_name" is the name of the package you want to install. YUM will automatically download the necessary package and all its dependencies from a configured repository.
YUM also provides other useful commands, such as "yum update" to update all installed packages, "yum remove" to remove a package, "yum list" to list all available packages, and more.
YUM allows you to configure multiple software repositories, each containing a different set of packages. This enables you to access a wide range of software packages from different sources and install them easily on your system. YUM is a powerful and flexible tool for managing software packages on Linux systems.

yum

<<apt
In Linux, APT (Advanced Package Tool) is a package management system used for installing, updating, and removing software packages on Debian-based distributions such as Debian, Ubuntu, and others.
APT is designed to simplify the process of managing software packages by resolving dependencies automatically. APT is capable of downloading packages from repositories and installing them on the system along with their dependencies.
With APT, you can install a package by simply running the command "apt-get install package_name", where "package_name" is the name of the package you want to install. APT will automatically download the necessary package and all its dependencies from a configured repository.
APT also provides other useful commands, such as "apt-get update" to update the package list from the configured repositories, "apt-get upgrade" to upgrade all installed packages, "apt-get remove" to remove a package, "apt-cache search" to search for packages, and more.
APT allows you to configure multiple software repositories, each containing a different set of packages. This enables you to access a wide range of software packages from different sources and install them easily on your system.
APT is a powerful and flexible tool for managing software packages on Linux systems, and it is widely used in Debian-based distributions.

apt

<<dpkg
In Linux, dpkg (Debian Package) is a low-level package management tool used for installing, configuring, and removing Debian packages on Debian-based distributions such as Debian, Ubuntu, and others.
dpkg is capable of installing and removing individual packages or groups of packages, and it can also be used to list installed packages and display package information.
With dpkg, you can install a package by running the command "dpkg -i package_name.deb", where "package_name.deb" is the name of the Debian package file. dpkg will install the package and its dependencies, but it will not automatically resolve any missing dependencies. If any dependencies are missing, dpkg will report an error and the installation will fail.
dpkg also provides other useful commands, such as "dpkg --configure package_name" to configure a package after installation, "dpkg --remove package_name" to remove a package, "dpkg -l" to list all installed packages, and more.
dpkg is a low-level tool and does not provide automatic dependency resolution, so it is typically used in conjunction with higher-level tools like APT to manage packages and dependencies more effectively. APT uses dpkg as its backend for package installation and removal.
dpkg

<<ssh
SSH (Secure Shell) is a protocol used for secure remote access to a computer or server over an unsecured network. SSH is commonly used in Linux and other Unix-like operating systems to provide secure access to remote shells, remote command execution, and file transfer.
When a user initiates an SSH connection to a remote computer, the connection is encrypted and authenticated using cryptographic methods. This ensures that the connection is secure and that the user's credentials are protected from eavesdropping or interception.
SSH can be used for various purposes, such as accessing a remote shell to execute commands on a remote computer, transferring files securely between computers, and establishing secure tunnels for accessing remote services.
To initiate an SSH connection, the user needs an SSH client, which is usually pre-installed on most Linux and Unix-like operating systems. The user also needs to know the remote computer's IP address or hostname, as well as the username and password or other authentication credentials required to access the remote system.
Overall, SSH provides a secure and reliable way to remotely access and manage Linux and other Unix-like systems, making it an essential tool for system administrators and other IT professionals.
ssh
<<telnet
Telnet is a protocol used for remote access to a computer or server over a network. It allows a user to establish a connection to a remote computer and interact with it as if they were sitting in front of it
Telnet has been widely used in the past for remote access, but its use has declined in recent years due to security concerns. Telnet sends data, including login credentials, in clear text, making it vulnerable to eavesdropping and interception. As a result, it is generally not recommended to use Telnet for remote access.
Instead, SSH (Secure Shell) is the preferred protocol for secure remote access. SSH uses encryption to protect the data transmitted over the network, providing a much more secure and reliable way to remotely access and manage systems.
While Telnet may still be supported on some systems for legacy reasons, it is generally recommended to use SSH or other secure protocols for remote access to avoid security risks.
telnet

<<ntp
NTP (Network Time Protocol) is a protocol used for synchronizing the time of computer clocks over a network. NTP allows computers to obtain accurate time information from a trusted time source and adjust their clocks accordingly.
Accurate time synchronization is important for many applications, such as financial transactions, scientific research, and network security. Without accurate time synchronization, it can be difficult to correlate events across multiple systems or ensure the accuracy of time-sensitive operations.
NTP uses a hierarchical system of time servers to ensure that time information is accurate and reliable. The highest-level servers obtain time information from atomic clocks or other trusted sources, and lower-level servers obtain time information from higher-level servers in the hierarchy. Clients can then obtain time information from one or more servers in the hierarchy, adjusting their clocks as needed to maintain accurate time.
NTP is widely used in Linux and other Unix-like operating systems to synchronize the time of system clocks with a trusted time source over a network. The protocol is designed to be scalable and resilient, allowing it to function effectively even in large and complex network environments.
Overall, NTP is a crucial tool for ensuring accurate time synchronization in networked environments, and it plays an important role in many applications and industries.
ntp
<<chrony
Chrony is a system daemon for Linux and other Unix-like operating systems that provides accurate timekeeping and synchronization with network time servers. Chrony is an alternative to the older NTP (Network Time Protocol) daemon and provides several improvements over NTP, including faster synchronization, better support for virtual machines, and improved accuracy.
Chrony uses a combination of techniques to synchronize the system clock with a network time server, including NTP and its own algorithm that adjusts the clock frequency to maintain accurate time. Chrony can operate in both server and client modes, allowing it to act as a time server for other systems or synchronize the time of local systems with a remote time server.
Chrony provides several features that make it a reliable and accurate time synchronization tool, such as support for multiple time sources, automatic selection of the best time source, and continuous monitoring of time sources for accuracy and reliability.
Chrony is widely used in Linux and other Unix-like operating systems to ensure accurate timekeeping and synchronization, particularly in environments where accurate time is critical, such as financial systems, scientific research, and network security.
Overall, Chrony is a powerful and flexible time synchronization tool that provides improved accuracy and reliability over traditional NTP implementations, making it an essential tool for many applications and industries.
chrony
<<dhcp
A DHCP (Dynamic Host Configuration Protocol) server is a network server that automatically assigns IP addresses and other network configuration information to client devices on a network. DHCP servers are commonly used in enterprise networks to simplify the management of IP address allocation and ensure that each device on the network has a unique IP address.
When a device joins a network that has a DHCP server, the server automatically assigns an IP address to the device based on available addresses in a predefined pool. The DHCP server can also provide other network configuration information, such as the subnet mask, default gateway, and DNS server addresses. This makes it easier for network administrators to manage network configurations and ensures that all devices on the network have the correct configuration settings.
DHCP servers typically work in conjunction with DHCP clients, which are built into many modern operating systems and networking devices. The client sends a request to the DHCP server when it joins the network, and the server responds with the appropriate configuration information.
Overall, a DHCP server is a critical component of a modern network infrastructure, as it simplifies the management of IP address allocation and helps to ensure that each device on the network has a unique IP address and the correct network configuration information.
dhcp

<<firewall
A firewall is a network security system that monitors and controls incoming and outgoing network traffic based on a set of predefined security rules. The primary purpose of a firewall is to protect a network from unauthorized access and attacks by filtering traffic that flows through it.

Firewalls can be implemented as hardware devices, software programs, or a combination of both. They can be configured to allow or deny traffic based on a range of criteria, including source and destination IP addresses, port numbers, protocols, and other characteristics of the network traffic.

Firewalls can be used to achieve several security objectives, including:

Preventing unauthorized access: Firewalls can block traffic from unauthorized sources and prevent attackers from gaining access to the network.

Controlling access: Firewalls can control access to specific network resources, such as servers, applications, and data.

Detecting and blocking attacks: Firewalls can detect and block known attacks, such as malware, viruses, and other types of malicious traffic.

Monitoring traffic: Firewalls can monitor network traffic and generate alerts for suspicious or anomalous behavior.

Enforcing security policies: Firewalls can enforce security policies that specify how traffic is allowed to flow through the network and what types of traffic are permitted.

Overall, the use of a firewall is to protect a network from unauthorized access and attacks by filtering traffic that flows through it, making it an essential component of network security infrastructure.

firewall

<<ldap
LDAP (Lightweight Directory Access Protocol) is a protocol used for accessing and maintaining distributed directory information services over an IP network. LDAP is commonly used in enterprise environments to centralize the management of user accounts, passwords, and other directory-related information.

In Linux, OpenLDAP is a popular implementation of the LDAP protocol that provides a lightweight and efficient way to manage user accounts and other directory-related information. OpenLDAP can be used to authenticate users and provide single sign-on capabilities across multiple systems and applications.

Here are some of the key features and uses of LDAP in Linux:

Centralized directory management: LDAP provides a centralized repository for storing and managing directory information, including user accounts, passwords, and other related data.

Scalability: LDAP is designed to be scalable, allowing it to handle large numbers of users and directory-related information with ease.

Security: LDAP supports a range of security features, including encryption, authentication, and access control, which help to ensure the confidentiality, integrity, and availability of directory information.

Integration with other systems: LDAP can be integrated with other systems and applications, such as email servers, web servers, and file servers, to provide a single sign-on experience for users.

Standardization: LDAP is an open standard, which means that it is widely supported by a range of software vendors and can be used across multiple platforms and operating systems.

Overall, the use of LDAP in Linux provides a centralized and efficient way to manage directory-related information, making it an essential component of many enterprise environments.
ldap

<<fdisk
fdisk is a command-line utility used in Linux and other Unix-like operating systems for managing disk partitions. It is used to create, delete, resize, and modify partitions on a hard disk.
When you run the fdisk command, it displays the partition table of the specified disk. You can then use various commands to create, delete, or modify partitions. Some of the commonly used commands in fdisk are:
n: Used to create a new partition
d: Used to delete a partition
p: Used to print the partition table
w: Used to write the changes to the disk
Here's an example of how to use fdisk to create a new partition on a hard disk:
Open a terminal and type sudo fdisk /dev/sda to launch fdisk and specify the hard disk you want to partition (in this case, /dev/sda).
Type p to print the current partition table and make sure there is unallocated space on the disk.
Type n to create a new partition.
Follow the prompts to specify the partition type, start and end sectors, and other options.
Type w to write the changes to the disk and exit fdisk.
After creating the new partition, you can use the mkfs command to format the partition with a filesystem such as ext4 or NTFS, and then mount the partition to make it accessible.
fdisk
<<lvm
LVM stands for Logical Volume Manager, a tool used for managing disk storage in Linux and other Unix-like operating systems. LVM provides a layer of abstraction between the physical disks and the file systems, allowing you to create, resize, and move logical volumes (LVs) dynamically without affecting the underlying physical disks or file systems.
Here are the main components of LVM:
Physical Volume (PV): A physical disk or disk partition that is used by LVM. Each PV is divided into one or more physical extents (PEs).
Volume Group (VG): A collection of one or more PVs that are combined into a single storage pool. A VG can be resized by adding or removing PVs.
Logical Volume (LV): A virtual disk that is created from one or more PEs in a VG. An LV can be resized or moved to a different PV within the same VG.
LVM Metadata: A small portion of the disk space that is reserved for storing information about the LVM configuration, such as the location of the PVs and LVs.
LVM provides several benefits, including:
Flexibility: LVM allows you to manage storage space dynamically, without the need to repartition the physical disks or move data between them.
Resilience: LVM provides features such as mirroring (RAID-1) and striping (RAID-0) to protect against disk failures.
Performance: LVM can improve disk I/O performance by allowing you to stripe data across multiple disks.
To use LVM, you need to install the LVM packages and create PVs, VGs, and LVs using the pvcreate, vgcreate, and lvcreate commands, respectively. You can then format the LVs with a file system and mount them as you would with regular disks.
lvm
<<fsck
fsck stands for File System Consistency Check. It is a command-line utility in Linux and other Unix-like operating systems that checks and repairs the consistency of a filesystem. When a filesystem is not unmounted cleanly or is not shut down properly, there may be inconsistencies in the filesystem, such as lost files, corrupted data, or unused blocks.
fsck can be used to scan the filesystem for inconsistencies and repair them. The fsck command can be run on both the root filesystem and on other mounted filesystems.
The basic syntax of the fsck command is:
fsck [options] filesystem
Here, filesystem is the name of the filesystem to be checked. Some commonly used options for fsck are:
-a: Automatically repair the filesystem without prompting for confirmation
-y: Assume "yes" to all prompts and automatically repair any issues
-r: Interactively repair the filesystem, prompting the user for confirmation before making changes
-V: Verbose output, displaying more detailed information during the check and repair process.
Here's an example of how to use the fsck command to check and repair a filesystem:
Open a terminal and unmount the filesystem you want to check with the following command:
umount /dev/sda1
Here, /dev/sda1 is the device name of the filesystem to be checked.
Run the fsck command with the appropriate options to check and repair the filesystem:
fsck -y /dev/sda1
This will automatically repair any issues found in the filesystem without prompting for confirmation.
Once the fsck command has completed, remount the filesystem with the following command:
mount /dev/sda1 /mnt
Here, /mnt is the mount point for the filesystem.
fsck

<<nfs
NFS (Network File System) is a protocol for sharing files between Linux and Unix systems over a network. It allows you to mount remote file systems on your local machine and access them as if they were part of your local file system. With NFS, you can share files and directories between multiple servers and clients, making it a popular choice for file sharing in enterprise environments.

To use NFS, you need to have the NFS server and client packages installed on your Linux system. Once you have installed the required packages, you can configure NFS to share a directory on the server and mount it on the client machine.

Here are the basic steps to configure NFS on Linux:

Install the NFS server and client packages on the server and client machines respectively.

Create a directory that you want to share on the server machine and set the appropriate permissions for it. For example:

bash
Copy code
mkdir /shared
chmod 777 /shared
Configure the NFS server by editing the /etc/exports file and adding an entry for the directory to be shared. For example:

bash
Copy code
/shared 192.168.1.0/24(rw,sync,no_subtree_check)
Here, /shared is the directory to be shared, 192.168.1.0/24 is the IP address range of the clients that are allowed to access the shared directory, and rw (read-write), sync, and no_subtree_check are the mount options for the shared directory.

Restart the NFS server to apply the changes:

Copy code
systemctl restart nfs-server
On the client machine, mount the shared directory using the mount command. For example:

bash
Copy code
mount -t nfs server:/shared /mnt
Here, server is the IP address or hostname of the NFS server and /mnt is the local mount point for the shared directory.

Access the shared directory on the client machine and verify that you can read and write files to it.

NFS is a powerful and flexible protocol that can be used for a variety of file sharing use cases. However, it is important to ensure that proper security measures are in place to prevent unauthorized access to shared files and directories.
nfs

<<samba server
Samba is an open-source software suite that provides file and print services to SMB/CIFS (Server Message Block/Common Internet File System) clients. It allows you to share files and printers between Linux, Windows, and other operating systems over a network.
To set up a Samba server on Linux, you can follow these steps:
Install the Samba package using your distribution's package manager. For example, on Ubuntu, you can run:
Copy code
sudo apt-get install samba
Create a directory that you want to share on the Samba server and set the appropriate permissions for it. For example:
bash
Copy code
sudo mkdir /srv/samba/share
sudo chown nobody:nogroup /srv/samba/share
sudo chmod 777 /srv/samba/share
Here, /srv/samba/share is the directory to be shared, and the nobody user and nogroup group are used for security reasons.
Configure Samba by editing the /etc/samba/smb.conf file. Here's a basic configuration that allows read/write access to the shared directory:
java
Copy code
[share]
path = /srv/samba/share
writable = yes
guest ok = yes
read only = no
create mask = 0777
directory mask = 0777
Here, [share] is the name of the share, path is the path to the shared directory, writable allows write access, guest ok allows guest access without a password, read only is set to no, and create mask and directory mask are used to set permissions on newly created files and directories.
Restart the Samba service to apply the changes:
sudo systemctl restart smbd
On a client machine, connect to the Samba share using the file manager or the smbclient command. For example:
smbclient //server/share
Here, server is the hostname or IP address of the Samba server, and share is the name of the shared directory.
Access the shared directory and verify that you can read and write files to it.
Samba is a powerful and flexible protocol that can be used for a variety of file sharing use cases. However, it is important to ensure that proper security measures are in place to prevent unauthorized access to shared files and directories.
samba server

<<root
In Linux, "root" is the superuser account that has complete control over the system. The root user can perform any system task, including installing and removing software, modifying system files and settings, and managing user accounts and permissions.
By default, the root account is disabled in most Linux distributions, and users are encouraged to use regular user accounts for everyday tasks. This is because running as root can be dangerous if a user accidentally executes a command that could harm the system or compromise its security.
To use the root account in Linux, you typically need to first enable it and set a password. This can be done by running the following command:
Copy code
sudo passwd root
You will be prompted to enter a new password for the root account. Once the password is set, you can switch to the root account using the su (short for "switch user") command:
Copy code
su -
You will be prompted to enter the root password. After entering the password, you will be logged in as the root user and can perform any task with full system privileges.
It is generally recommended to use the root account sparingly and only when necessary, and to use regular user accounts with restricted permissions for everyday tasks. This can help to minimize the risk of accidental damage to the system and improve overall security.
root

<<absolute path
In computing, an absolute path and a relative path are two ways of specifying the location of a file or directory in a file system.
An absolute path specifies the exact location of a file or directory from the root directory of the file system. It begins with a forward slash (/) on Unix-based systems (such as Linux) or a drive letter followed by a backslash (\) on Windows systems. For example, the absolute path of a file called myfile.txt located in the /home/user/documents directory on a Linux system would be /home/user/documents/myfile.txt.
absolute path

<<relative path
A relative path, on the other hand, specifies the location of a file or directory relative to the current working directory. It does not begin with a forward slash or a drive letter. Instead, it uses one or two dots (. and ..) to indicate the current directory and the parent directory, respectively. For example, if the current working directory is /home/user, the relative path to a file called myfile.txt located in the documents directory would be documents/myfile.txt.
Relative paths are often shorter and easier to read than absolute paths, but they can be more prone to errors if the current working directory is not known or changes frequently. Absolute paths, on the other hand, are always unambiguous and provide a complete specification of the location of a file or directory in the file system.
relative path

<<inode
An Inode number is a uniquely existing number for all the files in Linux and all Unix type systems.
When a file is created on a system, a file name and Inode number is assigned to it.
Generally, to access a file, a user uses the file name but internally file name is first mapped with respective Inode number stored in a table.
Note: Inode doesn't contain the file name. Reason for this is to maintain hard-links for the files. When all the other information is separated from the file name then only we can have various file names pointing to the same Inode.
inode

<<soft link
Symbolic Links
What is a Symbolic Link:
A symbolic or soft link is a string which is the pathname of the original file, in other words, a shortcut as we know it in Windows Operating System. This kind of link references virtual or path location of the original file but not the physical location.

Properties
The filename in the soft link is in essence the pathname to the original file, therefore the size of this link is only the length name of the file link. It is not the size of the original file.

Advantages:
The main advantage, as we just saw, is that it will not take much space since its size will be smaller.
Another advantage is that it can be created for directories and for different file systems.

Disadvantages:
Some real big disadvantages are that if the file is renamed, moved or deleted the link-file will become useless becoming a hanging link.

Command:
$ ln -s [original filename] [link name]
softlink

<<hard link
What is a Hard Link?
The first way is with a Hard Link. This way of making a connection is through what is called the indode, which is in essence is the reference to the physical location of the file. This means that the link-file has the same indode value as the original-file, making it a sort of "moving copy of the original-file".

Properties:
The properties of the hard link are that the link-file has the same size as the original file since it is a reference to the same location of the original file therefore not only a reference to it but also the same properties.

Advantages:
Since it is a reference to the file's physical location and not just to its current location, the link will remain available and will not be affected even if the original file is moved, renamed or deleted. In other words, if any of this things occur, the link-file will still access the information in the original file. The link-file will still work.

Disadvantages:
Hard Link's main disadvantage is it can not be created for a directory nor it can be created for files on different file systems.

Command:
$ ln [original filename] [link name]
hard link

<<ack
What is ACL ?
Access control list (ACL) provides an additional, more flexible permission mechanism for file systems. It is designed to assist with UNIX file permissions. ACL allows you to give permissions for any user or group to any disc resource.
Use of ACL :
Think of a scenario in which a particular user is not a member of group created by you but still you want to give some read or write access, how can you do it without making user a member of group, here comes in picture Access Control Lists, ACL helps us to do this trick.
Basically, ACLs are used to make a flexible permission mechanism in Linux.
From Linux man pages, ACLs are used to define more fine-grained discretionary access rights for files and directories.
setfacl and getfacl are used for setting up ACL and showing ACL respectively.
acl

<<wildcards

Percent ( % ) in a wildcard
The percent symbol is used in SQL to match any character (including an underscore) zero or more times.
Asterisk ( * ) in a wildcard
The asterisk in a wildcard matches any character zero or more times. For example, "comp*" matches anything beginning with "comp," which means "comp," "complete," and "computer" are all matched.
Question mark ( ? ) in a wildcard
A question mark matches a single character once. For example, "c?mp" matches "camp" and "comp." The question mark can also be used more than once. For example, "c??p" would match both of the above examples. In MS-DOS and the Windows command line, the question mark can also match any trailing question mark zero or one time. For example, "co??" would match all of the above matches, but because they are trailing question marks would also match "cop" even though it's not four characters.
Open and close brackets ( [ ] ) in a wildcard
With Unix shells, Windows PowerShell, and programming languages that support regular expressions, the open and close bracket wildcards match a single character in a range. For example, [a-z] matches any character "a" through "z," which means anything not in that range, like a number, would not be matched.
wildcards

<<gzip
gzip file.txt it is used to decrease the size of the file 
gzip -d file.txt.gz it is used to unzip the file
gzip

<<java life cycle
The Java application life cycle can be illustrated as in Figure 4.1, “The Java Life Cycle”. We can use any text editor to create the high-level Java text file. This file is saved as a .java file on the disk. We then compile this text file using the Java compiler, which result in a .class file being created on the disk. The .class file contains the bytecodes. The file is then loaded into memory by the class loader. The bytecode verifier confirms that the bytecodes are valid and not hostile. Finally, the JVM reads the bytecodes in memory and translates them into machine code.
you can see image in downloads
Writing the Java Program: In this phase, a programmer writes a Java program using any text editor or Integrated Development Environment (IDE) such as Eclipse, NetBeans, or IntelliJ IDEA.
Compiling the Java Program: In this phase, the Java source code is compiled into Java bytecode by the Java Compiler. The Java Compiler verifies the syntax and correctness of the Java code and generates Java bytecode that can be executed by the Java Virtual Machine (JVM).
Loading: In this phase, the class loader loads the bytecode of the compiled Java program into the JVM's memory.
Linking: In this phase, the JVM verifies the bytecode to ensure that it is valid and that all dependencies are resolved. It also allocates memory for the class variables and initializes them with their default values.
Initialization: In this phase, the static variables and static blocks of the Java program are initialized.
Execution: In this phase, the main method of the Java program is invoked, and the Java program starts executing. The Java program executes its code line by line until it terminates or throws an exception.
Unloading: In this phase, the JVM removes the Java program's bytecode and frees the memory allocated by it.
These phases represent the typical Java program lifecycle, which is performed automatically by the JVM.

The overall aim of the Java lifecycle is to execute a Java program in a reliable, efficient, and secure manner. The Java lifecycle consists of several phases, including writing the Java program, compiling the Java code, loading the class files, linking, initializing, and executing the Java program.
During each phase of the Java lifecycle, various checks and verifications are performed to ensure that the Java program is executed correctly and safely. For example, the Java compiler checks the syntax and correctness of the Java code, the class loader loads the bytecode of the compiled Java program into the JVM's memory, and the JVM verifies the bytecode to ensure that it is valid and that all dependencies are resolved.
By following the Java lifecycle, Java programs can be executed in a consistent and predictable manner, regardless of the underlying platform or operating system. The Java lifecycle also provides a secure execution environment, with built-in mechanisms for memory management, exception handling, and security. Overall, the aim of the Java lifecycle is to ensure that Java programs are executed efficiently, reliably, and securely.

#installing of java in ubuntu

sudo apt install default-jre it is used for java installation in ubuntu system
whereis java to see where is java installed
sudo apt list --installed to see the list of installed java


java life cycle

<<jvm
JVM, i.e., Java Virtual Machine.
JVM is the engine that drives the Java code.
Mostly in other Programming Languages, compiler produce code for a particular system but Java compiler produce Bytecode for a Java Virtual Machine.
When we compile a Java program, then bytecode is generated. Bytecode is the source code that can be used to run on any platform.
Bytecode is an intermediary language between Java source and the host system.
It is the medium which compiles Java code to bytecode which gets interpreted on a different machine and hence it makes it Platform/Operating system independent.
Reading Bytecode.
Verifying bytecode.
Linking the code with the library.

JVM generates a .class(Bytecode) file, and that file can be run in any OS, but JVM should have in OS because JVM is platform dependent.
Java is called platform independent because of Java Virtual Machine. As different computers with the different operating system have their JVM, when we submit a .class file to any operating system, JVM interprets the bytecode into machine level language.
JVM is the main component of Java architecture, and it is the part of the JRE (Java Runtime Environment).
A program of JVM is written in C Programming Language, and JVM is Operating System dependent.
JVM is responsible for allocating the necessary memory needed by the Java program.
JVM is responsible for deallocating memory space.

jvm

<<java application
mobile application- build android os
web based application- gmail,facebook etc
gaming application-2d games
distributed application-google myntra tcs 
cloud based application-building of aws etc
scientific application- scientfic calculations , mathematical calculations
enterprise and business application- clubs charity banks
desktop gui application - awt(abstract window toolkit),swing developing by using api(application program interface)
java application

<<java properties
simple
object oriented
Platform Independent and Architecture Neutral
portability
high performance
multithreaded
secure
robust
distributed
Interpreted
java properties

<<java project structure
source code - project structure- dependencies/libraries -test


<<maven
https://www.tutorialspoint.com/maven/maven_overview.htm
when code is written in java we need to deploy it java is written ,if server dont have java it wont work
it is based on pom (project object model all the project related information) it is in xml(extensible markup language) file
with maven we add dependencies(whatsapp - internet we have whatsapp we cat use without internet)
all the code cant be deployed so the code is converted intko jar or war
jar --> only java
war -->  along with java we have xml,html
ear --> combination of jar and ear
it is mostly used for java projects
maven is written in java
build tools
.net : visual stdio
c,c++: make file
java : Ant,maven,gradle

uses of maven 
it makes project easy to built
easy to add new dependencies
maven architecture
the tool helps get the right jar files for each project as there may be different versions of separate packages
source code -work space here we have goals mvn test mvn compile this is goal, after completing of this we get zar file ,we keep this jar file in local repo,from local repo to we can keep it in central or remote repo
maven life cycle
generate a resource - source code 
compile code - mvn compile 
test - mvn test
package - mvn package converting into jar file
install -mvn install jar file is in local repo
deploy (to server)
maven installation
java -version
mvm --version if we dont have it wont shown the it will ask to install or else
$ wget https://mirrors.estointernet.in/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
$ tar -xvf apache-maven-3.6.3-bin.tar.gz
$ mv apache-maven-3.6.3 /opt/
use this commands
maven built phases


maven
